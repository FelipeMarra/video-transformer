1st Bigram Model
    |_ Vocab Embedding table (vocab_size, vocab_size)

    Final loss: 3.39 (1500 steps, avg every 10 steps)

    Example Generation: 
        dpGfW; clsu&!BXph.aICtUSA;
        ps.uTJ lucTX,Vt
        LPMYvPXaMXKl!c
        sN'Zt
        X??,MJY3'e jAveT$KzOFwaIIwVB?beD vv!